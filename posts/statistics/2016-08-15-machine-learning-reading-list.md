---
title: machine learning reading list
date: 2016-08-15
---

# Machine Learning Reading List

Recently, I have been thinking about machine learning. This post is a list of the 
books I have been reading.  

- [Wasserman. All of Statistics](http://www.stat.cmu.edu/~larry/all-of-statistics/): 
This short book is a great introduction to statistics. Wasserman comments in the 
preface, *using fancy machine learning tools without understanding basic statistics 
is like doing brain surgery before knowing how to use a band aid.* Hyperbole aside, he 
has a point. Most machine learning algorithms are easy to understand if you know 
statistics. At the very least, if you understand basic statistics, you are unlikely to try and train 
a MNIST classifier using least squares\.\.\.\.

- [Bishop. Pattern Recognition and Machine 
Learning](http://www.springer.com/us/book/9780387310732):
This is a standard machine learning text. Covers all the basics and has tons of 
exercises.

- [Murphy. Machine Learning, A Probabilistic 
Perspective](https://www.cs.ubc.ca/~murphyk/MLbook/):
Also a standard text. Covers the same stuff as Bishop, but it is a little thicker. 
There is also matlab code for every single algorithm and figure in the book which is 
fantastic!

- [MacKay. Information Theory, Inference and Learning 
Algorithms](http://www.inference.phy.cam.ac.uk/mackay/itila/): This is my favorite 
book on the subject. MacKay is a master expositor. The number of pictures and examples 
is mind boggling. In my opinion, the exercises are more thoughtful than Bishop and 
Murphy.

- [Goodfellow, Bengio, Courville. Deep Learning](http://www.deeplearningbook.org/):
In the past few years, supervised deep learning has matured into a tool which many 
companies are using to extract value from their data. This book explains how to 
transform the beautiful statistical ideas behind neural networks into concrete 
software.

- [Goodman and Tenenbaum. Probabilistic Models of Cognition](https://probmods.org/): 
This book has a different flavor to the others. Code in a conventional programming 
language describes a sequence of machine instructions. Code in a probabilistic 
programming language describes a joint distribution. The compiler takes this code and 
returns machine code which samples from the joint distribution. Many machine learning 
problems can be expressed and solved inside probabilistic programming languages, so 
it is good to understand the basic idea, even if the technology doesn\'t scale well 
at this point.

